{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Part A\\\n",
    "\\\n",
    "Load the wspr.csv data set into a data frame. Are there any missing values?\n",
    "Perform any necessary data imputation on numerical data in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.a\n",
    "df = pd.read_table(\"/public/bmort/python/wspr.csv\", sep = \",\")\n",
    "\n",
    "# data imputation step: replacing all \"NaN\" with 0\n",
    "\n",
    "df.replace(\"NaN\", pd.NA, inplace=True)\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I notice that there are numerical values in the data frame that are 0 and there are categorical values in the data frame are are marked as \"NaN\". I will perform data imputation by replacing all \"NaN\" values with 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Part B\\\n",
    "\\\n",
    "\n",
    "Produce a table of summary statistics on the data set. How do the ranges of the\n",
    "values in the columns with numerical data compare? Does each column of numerical\n",
    "data have similar magnitudes and ranges? Are there any outliers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id           band         rx_lat         rx_lon  \\\n",
      "count  3.000000e+05  300000.000000  300000.000000  300000.000000   \n",
      "mean   6.554775e+09      11.575247      41.067491     -60.402133   \n",
      "std    9.996265e+04      57.971250      13.644301      59.148742   \n",
      "min    6.554620e+09      -1.000000     -70.646000    -157.958000   \n",
      "25%    6.554701e+09       7.000000      38.104000    -105.958000   \n",
      "50%    6.554774e+09      10.000000      41.771000     -79.875000   \n",
      "75%    6.554847e+09      14.000000      47.688000       0.292000   \n",
      "max    6.557023e+09    2400.000000      68.354000     175.875000   \n",
      "\n",
      "              tx_lat         tx_lon       distance        azimuth  \\\n",
      "count  300000.000000  300000.000000  300000.000000  300000.000000   \n",
      "mean       39.733674     -62.201610    2275.101273     177.455867   \n",
      "std        13.304164      56.596384    2172.390931     110.816167   \n",
      "min       -87.521000    -173.042000       0.000000       0.000000   \n",
      "25%        34.729000     -99.042000     889.000000      69.000000   \n",
      "50%        40.479000     -81.208000    1584.000000     177.000000   \n",
      "75%        46.063000      -2.208000    2917.000000     286.000000   \n",
      "max        89.479000     178.958000   18925.000000     359.000000   \n",
      "\n",
      "          rx_azimuth     frequency          power            snr  \\\n",
      "count  300000.000000  3.000000e+05  300000.000000  300000.000000   \n",
      "mean      179.843257  1.176180e+07      26.495313     -14.758777   \n",
      "std       103.073055  5.796213e+07       7.315485       9.153760   \n",
      "min         0.000000  1.374120e+05       0.000000     -40.000000   \n",
      "25%        84.000000  7.040040e+06      23.000000     -22.000000   \n",
      "50%       180.000000  1.014010e+07      23.000000     -16.000000   \n",
      "75%       279.000000  1.409709e+07      33.000000      -9.000000   \n",
      "max       359.000000  2.400070e+09     103.000000      42.000000   \n",
      "\n",
      "               drift           code  \n",
      "count  300000.000000  300000.000000  \n",
      "mean       -0.058890       1.044613  \n",
      "std         0.555724       0.330983  \n",
      "min        -4.000000      -1.000000  \n",
      "25%         0.000000       1.000000  \n",
      "50%         0.000000       1.000000  \n",
      "75%         0.000000       1.000000  \n",
      "max         4.000000       8.000000  \n"
     ]
    }
   ],
   "source": [
    "# 1.b\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The data is very volatile in my opinion. There are means that are positive, negative, and some averages have very large distances between other averages. The biggest outlier I can see is frequency column. It by far has the largest numerical values in the summary statistics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Part C\\\n",
    "\\\n",
    "How many unique values are in each of the following columns: band, rx_sign, and\n",
    "tx_sign?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "891\n",
      "1070\n"
     ]
    }
   ],
   "source": [
    "# 1.c\n",
    "\n",
    "count = 0\n",
    "for i in range(len(df.band.unique())):\n",
    "    count +=1\n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(df.rx_sign.unique())):\n",
    "    count +=1\n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(df.tx_sign.unique())):\n",
    "    count +=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The column band has 23 unique values, the column rx_sign has 891 unique values, and the column tx_sign has 1070 unique values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Part D\\\n",
    "\\\n",
    "What is the average distance (in km) between the transmitting station and the\n",
    "receiving station for signals that have a power less than 30 dBm?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057.334727356264\n"
     ]
    }
   ],
   "source": [
    "#1.d\n",
    "avg_30 = []\n",
    "\n",
    "for i in range(len(df.distance)):\n",
    "    if df.power[i] < 30:\n",
    "        avg_30.append(df.distance[i])\n",
    "print(sum(avg_30) / len(avg_30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The average distance between the transmitting station and the receiving station for signals that have a power less than 30dBm is\n",
    "2057.334727356264 km.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Part E \\\n",
    "\\\n",
    "What is the call sign of the receiving station that received the most signal\n",
    "transmissions on the 14 MHz band (i.e. band = 14) during the ten-minute period of\n",
    "1:00 – 1:10 UTC? Hint: Use Python’s datetime library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFS\n"
     ]
    }
   ],
   "source": [
    "# 1.e\n",
    "import pandas as pd\n",
    "\n",
    "df['time'] = pd.to_datetime(df['time'])  \n",
    "\n",
    "filtered_df = df[(df['band'] == 14) & \n",
    "    (df['time'].dt.time >= pd.to_datetime('1:00').time()) & \n",
    "    (df['time'].dt.time <= pd.to_datetime('1:10').time())]\n",
    "\n",
    "max_call_sign = filtered_df['rx_sign'].value_counts().idxmax()\n",
    "\n",
    "print(max_call_sign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "KFS is the call sign of the receiving station that received the most signal transmissions on the 14 MHz band during the ten-minute of 1:00 - 1:10 UTC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Part F \\\n",
    "\\\n",
    "Partition the WSPR data set so that a random sample of 80% of the data will be used for training and 20% will be used for testing your machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.f\n",
    "train, test = train_test_split(df, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Part G\\\n",
    "\\\n",
    "Using Python’s scikit-learn library, generate a linear regression model to predict the\n",
    "signal-to-noise ratio from the distance, frequency, and power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -20.244745492655323\n",
      "Coefficients: [-1.07415430e-03  1.25381904e-09  2.98849527e-01]\n"
     ]
    }
   ],
   "source": [
    "# 1.g\n",
    "\n",
    "X_train = train[['distance', 'frequency', 'power']]\n",
    "y_train = train['snr']\n",
    "\n",
    "X_test = test[['distance', 'frequency', 'power']]\n",
    "y_test = test['snr']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print('Intercept:', model.intercept_)\n",
    "print('Coefficients:', model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The linear regression model for the signal-to-noise ratio based distance, frequency, and power in the WSPR data set is: $\\hat{y} = -20.24474549265532 - 1.07415430*10^{-3}X_1 - 1.25381904*10^{-9}X_2 + 2.98849527*10^{-1}X_3$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Part H \\ \n",
    "\\\n",
    "\\\n",
    "Use the 20% of the data set aside for testing to determine the accuracy of your\n",
    "model. Choose an appropriate accuracy metric. How well does your model predict\n",
    "the signal to noise values from distance, frequency, and power? Comment on why\n",
    "the accuracy is good or poor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 75.18509424244381\n",
      "R-squared: 0.1022570484041998\n"
     ]
    }
   ],
   "source": [
    "# 1.h\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The accuracy metrics I used for this test data are mean squared error and $r^2$ score. Having a lower mean squared error means there is more accurate data. Having an $r^2$ score closer to one indicates the model is a good fit for the data. In the case of the training data the mean squared error is 75.19 and the $r^2$ score is 0.10. I believe from the two values given that the accuracy of this linear regression is poor. The linear regression does not fit the data well and the mean squared error is high which means there are a lot of outliers that may be affecting this linear regression model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Part I \\ \n",
    "\\\n",
    "\\\n",
    "What is the predicted signal to noise value for a receiver that is located 2,000 km\n",
    "from a transmitter that uses a frequency of 14,030,000 Hz and a power level of 31\n",
    "dBm? How confident are you in the answer? Explain your reasoning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.i\n",
    "\n",
    "prediction = -20.24474549265532 - 1.07415430*10**(-3)*2000 - \\\n",
    "    1.25381904*10**(-9)*14030000 + 2.98849527*10**(-1)*31\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The predicted signal-to-noise ratio is -13.14630983678652\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (anaconda3 2023.07-2)",
   "language": "python",
   "name": "anaconda3-2023.07-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
